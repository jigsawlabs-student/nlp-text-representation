{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Normalization and Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we saw how we can translate text into a document vector by mapping each word in a corpus to a corresponding index.  Now one issue with representing each token as a different feature, is the shear number of features that we have to work with.  For example, with using the CountVectorizor on our newsgroup dataset, each document had over $130,000$ features, one for each token in the vocabulary of the corpus.\n",
    "\n",
    "In this lesson, we'll learn different techniques for reducing the number of features in our vectors, while still retaining the valuable information that allows our models to learn from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the list above, it looks like including the stop words allowed us to limit the document to some high value words.  But notice that we are representing words like `door` and `doors` separately.   For the purpose of our classifying a document, it would probably be best for our transformer to recognize that this is essentially the same word counted twice, instead of two different words.  We can accomplish this through text normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Text normalization** is the process of transforming text into a single canonical form that it might not have had before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One technique to accomplish this is with stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope grouping together words with essentially the same meaning, and often includes the removal of derivational affixes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With stemming, we would group `sing`, `sings` and `singing` as the same word.  Below is an example of some sample text, and how a stemmer would transform it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"porter-stemmer.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas stemming uses a set of rules to apply to each words, with lemmatization, we get to the root word by often using a predefined dictionary.  Lemmatization may also use a word's parts-of-speech, such as whether the word is being used as a noun or verb, to reduce  the word correctly.  \n",
    "\n",
    "Let's see an example of how stemming and lemmatization would come to different results.  With lemmatization, \"better\" has \"good\" as its lemma, so the word is reduced to \"good\".  With stemming, by contrast the words would be different.  Both techniques, however, would reduce the word \"walking\" to \"walk\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we learned about two different techniques to perform text normalization, through both stemming and lemmatization.  With stemming, the text is preprocessed through a set of rules designed to make words more standard.  Different endings of words are removed so that when the root words are the same, they are more often represented as the same.  \n",
    "\n",
    "Lemmatization attempts to achieve the same goal but through a different technique.  It uses a predefined dictionary that maps the word to it's root word. Lemmatization may also consider parts of speech in extracting the meaning of a word.  For example, `chilled` generally means cold, while `chill` is more associated with relaxed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Stemming Stanford](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Using Spacy](dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Spacy Dataquest](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
