{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./Reviews.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "coconut_df = pd.read_csv('./coconut_water.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "coconut_water.to_csv('./coconut_water.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(top_product, df[df.ProductId == top_product].Score.var()) for top_product in top_products]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the `Score` as our target and the Text as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words to Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47836    Must admit the taste of O.N.E. coconut water i...\n",
       "47837    I love this stuff!  Perfect blend of dark choc...\n",
       "47838    I am from the Philippines, a country where the...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coconut_df.Text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with bag of words, and then we'll move to term frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = coconut_df.Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(document):\n",
    "    terms = [term.lower() for term in document.split()]\n",
    "    dictionary = dict.fromkeys(terms, 0)\n",
    "    for term in terms:\n",
    "        dictionary[term] += 1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'must': 1,\n",
    "#  'admit': 1,\n",
    "#  'the': 2,\n",
    "#  'taste': 1,\n",
    "#  'of': 2,\n",
    "#  'o.n.e.': 1,\n",
    "#  'coconut': 2,\n",
    "#  'water': 1,\n",
    "#  'is': 1,\n",
    "#  'better.': 1,\n",
    "#  'took': 1,\n",
    "#  'a': 1,\n",
    "#  'long': 1,\n",
    "#  'time': 1,\n",
    "#  'to': 1,\n",
    "#  'get': 1,\n",
    "#  'through': 1,\n",
    "#  'supply': 1,\n",
    "#  'water.': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's incorporate use of spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(document)\n",
    "[token.lemma_ for token in doc if token.is_alpha and not token.is_stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's return a bag of the lemma's of the words instead of the pure words, and only include the word if it is not a stop word, according to spacy, and it *is* an alphabetical term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "def bag_of_words(document):\n",
    "    terms = [term.lemma_ for term in nlp(document) if term.is_alpha and not term.is_stop]\n",
    "    dictionary = dict.fromkeys(terms, 0)\n",
    "    for term in terms:\n",
    "        dictionary[term] += 1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admit': 1,\n",
       " 'taste': 1,\n",
       " 'coconut': 2,\n",
       " 'water': 2,\n",
       " 'well': 1,\n",
       " 'take': 1,\n",
       " 'long': 1,\n",
       " 'time': 1,\n",
       " 'supply': 1}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words(document)\n",
    "\n",
    "# {'admit': 1,\n",
    "#  'taste': 1,\n",
    "#  'coconut': 2,\n",
    "#  'water': 2,\n",
    "#  'well': 1,\n",
    "#  'take': 1,\n",
    "#  'long': 1,\n",
    "#  'time': 1,\n",
    "#  'supply': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move from bag of words to term frequency.  \n",
    "> Divide each term by the total number of terms counted in bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(document):\n",
    "    terms = [term.lemma_ for term in nlp(document) if term.is_alpha and not term.is_stop]\n",
    "    doc_length = len(terms)\n",
    "    dictionary = dict.fromkeys(terms, 0)\n",
    "    for term in terms:\n",
    "        dictionary[term] += 1/doc_length\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admit': 0.09090909090909091,\n",
       " 'taste': 0.09090909090909091,\n",
       " 'coconut': 0.18181818181818182,\n",
       " 'water': 0.18181818181818182,\n",
       " 'well': 0.09090909090909091,\n",
       " 'take': 0.09090909090909091,\n",
       " 'long': 0.09090909090909091,\n",
       " 'time': 0.09090909090909091,\n",
       " 'supply': 0.09090909090909091}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequency(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use inverse document frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that: \n",
    "    \n",
    "$idf(term) = \\log(\\frac{\\text{# of documents}}{\\text{# of documents with term}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by writing a function called document frequency.  This should calculate the number of documents that a term appears in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_frequency(term):\n",
    "    return sum([term in doc_word for doc_word in doc_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_frequency('salty')\n",
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_frequency('water')\n",
    "# 286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from here, let's write a function called `inverse_document_frequency`.  It should take in arguments of `term` and `doc_length`, and return the inverse document frequency score for a term.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def inverse_document_frequency(term, doc_length = 456):\n",
    "    return np.log(doc_length/document_frequency(term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4665009986945335"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_document_frequency('water', doc_length = 456)\n",
    "# 0.4665009986945335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.513054897080286"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_document_frequency('salty', doc_length = 456)\n",
    "# 4.513054897080286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Dictionary of Inverse Document Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the inverse document frequency is constant for each term, regardless of the document.  So, we'll create a dictionary of each word along with the inverse document frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2469"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_words = [list(tf.keys()) for tf in tfs]\n",
    "unique_words = list(set(terms))\n",
    "\n",
    "len(unique_words)\n",
    "# 2469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = dict([(word, inverse_document_frequency(word, doc_length = 456)) for word in unique_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If we order the words from lowest to highest, we can find the words that occur most frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coconut    0.449170\n",
       "water      0.466501\n",
       "taste      0.480586\n",
       "like       0.870219\n",
       "drink      0.902137\n",
       "Zico       1.022626\n",
       "good       1.066247\n",
       "flavor     1.132060\n",
       "try        1.145759\n",
       "love       1.239691\n",
       "bottle     1.270463\n",
       "product    1.386294\n",
       "buy        1.507372\n",
       "great      1.558145\n",
       "well       1.691676\n",
       "dtype: float64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_series = pd.Series(idfs)\n",
    "\n",
    "idf_series.sort_values(ascending = True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's write a function called `tf_idf` that takes in a document and returns a dictionary of the `tf_idf` of the terms in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(document):\n",
    "    tf_dict = term_frequency(document)\n",
    "    return {term:tf_dict[term]*idf_dict[term] for term in tf_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_document =  documents.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "supply     0.493577\n",
       "admit      0.456716\n",
       "long       0.267676\n",
       "take       0.238726\n",
       "time       0.200952\n",
       "well       0.153789\n",
       "water      0.084818\n",
       "coconut    0.081667\n",
       "taste      0.043690\n",
       "dtype: float64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(tf_idf(first_document)).sort_values(ascending = False)\n",
    "\n",
    "# supply     0.493577\n",
    "# admit      0.456716\n",
    "# long       0.267676\n",
    "# take       0.238726\n",
    "# time       0.200952\n",
    "# well       0.153789\n",
    "# water      0.084818\n",
    "# coconut    0.081667\n",
    "# taste      0.043690\n",
    "# dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "choc          0.374438\n",
       "stuff         0.239569\n",
       "cow           0.211120\n",
       "intolerant    0.211120\n",
       "lactose       0.173237\n",
       "forward       0.163317\n",
       "milk          0.156713\n",
       "case          0.156713\n",
       "dark          0.139416\n",
       "smooth        0.131721\n",
       "blend         0.128434\n",
       "perfect       0.120118\n",
       "refresh       0.111452\n",
       "close         0.103000\n",
       "look          0.087551\n",
       "come          0.074871\n",
       "think         0.071705\n",
       "well          0.058334\n",
       "buy           0.051978\n",
       "love          0.042748\n",
       "drink         0.031108\n",
       "like          0.030008\n",
       "water         0.016086\n",
       "coconut       0.015489\n",
       "dtype: float64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(tf_idf(documents.iloc[1])).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can begin to see that using TF-IDF is good for judging what makes each document unique.  In our second document, words like `water`, `coconut` and drink are towards the bottom, while words like `lactose` and `intolerant` are closer to the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
