{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words and Bag of NGrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating Low Value Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading up our newsgroups dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "documents = pd.Series(newsgroups_train['data'])\n",
    "y = newsgroups_train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Stop words** are commonly occurring words believed to contain little information that we remove from our document vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to ignore stop words in our CountVectorizer, we can ignore stop words with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a sense of the how the CountVectorizer reduced the text to by calling `inverse_transform`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remember there originally was the phrase, \"looked to be from the late 60s\", and now many of those words are gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['15', '60s', '70s', 'addition', 'body', 'bricklin', 'brought',\n",
       "        'bumper', 'called', 'car', 'college', 'day', 'door', 'doors',\n",
       "        'early', 'edu', 'engine', 'enlighten', 'funky', 'history', 'host',\n",
       "        'il', 'info', 'know', 'late', 'lerxst', 'lines', 'looked',\n",
       "        'looking', 'mail', 'maryland', 'model', 'neighborhood', 'nntp',\n",
       "        'organization', 'park', 'posting', 'production', 'rac3', 'really',\n",
       "        'rest', 'saw', 'separate', 'small', 'specs', 'sports', 'subject',\n",
       "        'tellme', 'thanks', 'thing', 'umd', 'university', 'wam',\n",
       "        'wondering', 'years'], dtype='<U180')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizor.inverse_transform(X[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tradeoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With both stop words and n-grams, there are costs and benefits to employing them.  \n",
    "\n",
    "* Stop words\n",
    "\n",
    "\n",
    "\n",
    "* Bag of N-grams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
