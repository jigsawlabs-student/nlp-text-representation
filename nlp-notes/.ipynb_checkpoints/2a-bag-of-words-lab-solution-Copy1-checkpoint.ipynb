{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we'll practice using the bag of words model using a corpus that consists of tweets about an airline.  Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/jigsawlabs-student/nlp-text-representation/master/Tweets.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of the content in our dataset.  Select the first three rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                        0.0  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:3]\n",
    "\n",
    "# \ttweet_id\tairline_sentiment\tairline_sentiment_confidence\tnegativereason\tnegativereason_confidence\tairline\tairline_sentiment_gold\tname\tnegativereason_gold\tretweet_count\ttext\ttweet_coord\ttweet_created\ttweet_location\tuser_timezone\n",
    "# 0\t570306133677760513\tneutral\t1.0000\tNaN\tNaN\tVirgin America\tNaN\tcairdin\tNaN\t0\t@VirginAmerica What @dhepburn said.\tNaN\t2015-02-24 11:35:52 -0800\tNaN\tEastern Time (US & Canada)\n",
    "# 1\t570301130888122368\tpositive\t0.3486\tNaN\t0.0\tVirgin America\tNaN\tjnardino\tNaN\t0\t@VirginAmerica plus you've added commercials t...\tNaN\t2015-02-24 11:15:59 -0800\tNaN\tPacific Time (US & Canada)\n",
    "# 2\t570301083672813571\tneutral\t0.6837\tNaN\tNaN\tVirgin America\tNaN\tyvonnalynn\tNaN\t0\t@VirginAmerica I didn't today... Must mean I n...\tNaN\t2015-02-24 11:15:48 -0800\tLets Play\tCentral Time (US & Canada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dataset consists of different contents about an airline.  The airline sentiment has already been classified, and the text has the content of each tweet.\n",
    "\n",
    "Let's assign `documents` to equal the column of text, and assign `sentiment` to equal the `airline_sentiment` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = df.airline_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     neutral\n",
       "1    positive\n",
       "2     neutral\n",
       "Name: airline_sentiment, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment[:3]\n",
    "# 0     neutral\n",
    "# 1    positive\n",
    "# 2     neutral\n",
    "# Name: airline_sentiment, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's get an overview of the different `sentiment` values by calling `value_counts` on that series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that most of the reviews are negative.  Bummer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we know we need all of the feature and target values to be numeric.  For coercing the text, we'll need our nlp techniques.  But we should be make the target numeric using our knowledge of pandas.  Change the target so that the negative is represented by 0, neutral by 1, and positive by 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assign the coerced series to the variable `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {'negative': 0, 'neutral': 1, 'positive': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    1\n",
       "3    0\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.airline_sentiment.map(sentiment_map)\n",
    "y[:4]\n",
    "\n",
    "# 0    1\n",
    "# 1    2\n",
    "# 2    1\n",
    "# 3    0\n",
    "# Name: airline_sentiment, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9178\n",
       "1    3099\n",
       "2    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employ Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll need to coerce our documents to be represented by a bag of words.  Load the CountVectorizer from the `feature_extraction.text` module.  Then assign an instance of the CountVectorizer to the variable `bow_vectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the transformed bag of words documents to the variable `X_vectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectors = bow_vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vectors.toarray()[:2]\n",
    "\n",
    "# array([[0, 0, 0, ..., 0, 0, 0],\n",
    "#        [0, 0, 0, ..., 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a sense of which words were encoded by using the `vocabulary_` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = bow_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('virginamerica', 14273), ('what', 14551), ('dhepburn', 4804)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab.items())[:3]\n",
    "\n",
    "# [('virginamerica', 14273), ('what', 14551), ('dhepburn', 4804)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, that this displays the list of each encoded token, and the associated index.  Show this by retrieving the number of times that `VirginAmerica` appears in the first tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vectors.toarray()[0][14273]\n",
    "\n",
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, enough messing around.  Now let's split our data into a training and test set, also using the `stratify` argument, so that sentiments are split equally between our training and test sets.  Set the test size to .2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y, stratify = y, test_size = .2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11712, 15051), (2928, 15051))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape\n",
    "\n",
    "# ((11712, 15051), (2928, 15051))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's look at the value counts of y in the test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    0.626878\n",
       " 1    0.211663\n",
       " 2    0.161458\n",
       " Name: airline_sentiment, dtype: float64,\n",
       " 0    0.627049\n",
       " 1    0.211749\n",
       " 2    0.161202\n",
       " Name: airline_sentiment, dtype: float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize = True), y_test.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's initialize a logistic regression model, train it, setting the `max_iter` to 500.\n",
    "\n",
    "> Assign the model to the variable `lr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the accuracy of the model on the test dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.798155737704918"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)\n",
    "\n",
    "# 0.798155737704918"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a multiclassification model like we have here, there are three different sets of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 15051)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see that there are three sets of features trained, one to predict the negative reviews, then to predict the neutral, and finally to predict the positive reviews.  \n",
    "\n",
    "Let's select the first list of coefficients, look at associated feature names, and sort them from highest to lowest, selecting the top 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst           2.214460\n",
       "nothing         1.543403\n",
       "delayed         1.463210\n",
       "hours           1.414857\n",
       "ridiculous      1.399412\n",
       "terrible        1.362820\n",
       "fail            1.351004\n",
       "suck            1.347511\n",
       "unacceptable    1.335372\n",
       "sucks           1.291287\n",
       "fix             1.266558\n",
       "answer          1.259342\n",
       "unless          1.231424\n",
       "paid            1.229213\n",
       "hold            1.228098\n",
       "rude            1.219338\n",
       "worse           1.208478\n",
       "disappointed    1.204609\n",
       "luggage         1.179982\n",
       "frustrated      1.179896\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lr.coef_[0], bow.get_feature_names()).sort_values(ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same thing for features of the positive tweets.  Select the top twenty features of the positive tweets and display their corresponding scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thank         2.224737\n",
       "awesome       2.152502\n",
       "thanks        2.013645\n",
       "great         1.828529\n",
       "worries       1.812265\n",
       "thnx          1.693800\n",
       "amazing       1.672030\n",
       "excellent     1.670677\n",
       "best          1.667961\n",
       "love          1.666248\n",
       "cool          1.548519\n",
       "appreciate    1.522806\n",
       "thx           1.501574\n",
       "wonderful     1.489044\n",
       "kudos         1.363512\n",
       "thankful      1.302682\n",
       "loved         1.221681\n",
       "refunded      1.215347\n",
       "happy         1.166732\n",
       "sweet         1.152855\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lr.coef_[-1], bow.get_feature_names()).sort_values(ascending = False)[:20]\n",
    "\n",
    "# thank         2.224737\n",
    "# awesome       2.152502\n",
    "# thanks        2.013645\n",
    "# great         1.828529\n",
    "# worries       1.812265\n",
    "# thnx          1.693800\n",
    "# amazing       1.672030\n",
    "# excellent     1.670677\n",
    "# best          1.667961\n",
    "# love          1.666248\n",
    "# cool          1.548519\n",
    "# appreciate    1.522806\n",
    "# thx           1.501574\n",
    "# wonderful     1.489044\n",
    "# kudos         1.363512\n",
    "# thankful      1.302682\n",
    "# loved         1.221681\n",
    "# refunded      1.215347\n",
    "# happy         1.166732\n",
    "# sweet         1.152855\n",
    "# dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's move to using ngrams and stop words in our model.  Initialize a new CountVectorizer, this time that splits our document into tokens of length one and two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "ngram_vectorizor = CountVectorizer(ngram_range = (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ngrams = ngram_vectorizor.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are now many more features to represent each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 117630)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ngrams.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Initially, we only had 15000 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15051)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's split our model into training and test sets, still using `stratify`, and setting the `test_size` to .2.  Set the `random_state` to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_ngrams, X_test_ngrams, y_train_ngrams, y_test_ngrams = train_test_split(X_ngrams, y,\n",
    "                                                                                stratify = y, test_size = .2, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a new logistic regression model, setting the maximum iterations to 1000.  Train the model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_ngrams = LogisticRegression(max_iter = 1000).fit(X_train_ngrams, y_train_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8155737704918032"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_ngrams.score(X_test_ngrams, y_test_ngrams)\n",
    "# 0.8114754098360656"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we perform slightly better using bag of ngrams text representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the top thirty features of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "on hold                1.616944\n",
       "the worst              1.324803\n",
       "late flight            1.214466\n",
       "my bag                 1.159465\n",
       "cancelled flightled    1.119606\n",
       "due to                 1.076597\n",
       "my luggage             1.049506\n",
       "cancelled flighted     1.036410\n",
       "with no                0.923594\n",
       "no one                 0.906188\n",
       "customer service       0.903545\n",
       "late flightr           0.896845\n",
       "is not                 0.871396\n",
       "this is                0.847528\n",
       "my bags                0.844569\n",
       "call back              0.836916\n",
       "and no                 0.815591\n",
       "delayed flight         0.785795\n",
       "waiting for            0.779686\n",
       "no response            0.768646\n",
       "usairways you          0.759591\n",
       "hour delay             0.755366\n",
       "usairways your         0.754920\n",
       "still waiting          0.748263\n",
       "an hour                0.737140\n",
       "for hours              0.732473\n",
       "not even               0.731768\n",
       "why do                 0.730159\n",
       "united not             0.706476\n",
       "had to                 0.706439\n",
       "dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lr_ngrams.coef_[0], ngram_vectorizor.get_feature_names()).sort_values(ascending = False)[:30]\n",
    "\n",
    "# delayed         1.565812\n",
    "# worst           1.341883\n",
    "# nothing         1.245329\n",
    "# hours           1.237040\n",
    "# sucks           1.138270\n",
    "# delay           1.137530\n",
    "# not             1.098006\n",
    "# doesn           1.092324\n",
    "# no              1.073342\n",
    "# lost            1.062731\n",
    "# suck            1.060646\n",
    "# luggage         0.982798\n",
    "# rude            0.955572\n",
    "# why             0.954224\n",
    "# stop            0.933671\n",
    "# again           0.928162\n",
    "# terrible        0.923423\n",
    "# bags            0.905553\n",
    "# hour            0.903597\n",
    "# days            0.864337\n",
    "# cancelled       0.849927\n",
    "# website         0.849439\n",
    "# answer          0.834583\n",
    "# ridiculous      0.833111\n",
    "# customers       0.818718\n",
    "# the worst       0.810770\n",
    "# paid            0.799298\n",
    "# unacceptable    0.799168\n",
    "# hrs             0.799022\n",
    "# fail            0.795682\n",
    "# dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, without much guidance, use the `CountVectorizer` along with stop words.  Split the model into training and test sets, and see how the model scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "ngram_vectorizor_stop = CountVectorizer(ngram_range = (1, 2), stop_words=ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ngram_stop = ngram_vectorizor_stop.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lr_stop_X_train, lr_stop_X_test, lr_stop_y_train, lr_stop_y_test = train_test_split(X_ngram_stop, y, stratify = y, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 1000).fit(lr_stop_X_train, lr_stop_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model performs slightly worse with the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7916666666666666"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(lr_stop_X_test, lr_stop_y_test)\n",
    "# 0.7817622950819673"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Bonus:  \n",
    "\n",
    "Even though we may train a worse model as we have a longer sequence of ngrams, we may be able to get a better understanding of what's leading to positive or a negative sentiment.  Change the ngram range above to 2, 3, so that we don't train on any individual sequences.  Then look at the most influential negative features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we practiced using the `CountVectorizer` in sklearn.  We saw that we can use it to both classify tweets as positive or negative, and to understand what is the cause of positive or negative tweets.  We specified parameters such as `ngram_range` and `stop_words` in our CountVectorizer.  We found a logistic regression model performed the best without the use of stop words, and with an `ngram_range` of (1, 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[5 part Spacy Tutorial](https://medium.com/@makcedward/nlp-pipeline-stop-words-part-5-d6770df8a936)\n",
    "\n",
    "[Kaggle Amazon Food Reviews](https://www.kaggle.com/snap/amazon-fine-food-reviews)\n",
    "\n",
    "[Spacy](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
