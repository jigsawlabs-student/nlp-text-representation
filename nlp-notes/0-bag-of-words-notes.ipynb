{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sentiment analysis - \n",
    "    * Positive/Negative\n",
    "2. Topics\n",
    "\n",
    "* Cars, Sports, Cooking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by loading up some data from the newsgroups dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "documents = pd.DataFrame(newsgroups_train['data'], columns = ['text'])\n",
    "y = newsgroups_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsgroups_train['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_document = documents['text'][0]\n",
    "first_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document -> [will, \"not\", \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an NLP problem, an observation like this is referred to as a **document**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In NLP, a **document** is a distinct text. This generally means that each article, book, or so on is its own document.  It is the equivalent of an observation in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**segmentation** break our document into chunks, whether sentences, or lines, or heading, body and footer, it's called .  \n",
    "\n",
    ">  A **token** is a string of contiguous characters between two spaces.\n",
    "\n",
    "* `will not`-> `will` and `not`\n",
    "* `won't` -> `won`, `'t`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WHAT', 'car', 'is', 'this!?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc = str.split(first_document)\n",
    "tokenized_doc[6:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "what -> 2, car -> 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_document = \"What car is this\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[0, 0, 1, 0, 1, ]\n",
    "[0, 1, 0, 0, 2]\n",
    "[0, 1, 0, 1, 1]\n",
    "#      what  #car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* bag of words\n",
    "\n",
    "* Histogram: {'what': 1, 'car': 2, 'is': 5}\n",
    "    \n",
    "[0, 0, 1, 0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Each Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer =CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(newsgroups_train['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37780"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[1].toarray()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The way that we translate our words into text is called **text representation**.  And when we represent our documents as a vector, its called a **vector space model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer() \n",
    "X = vectorizer.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['from', 'lerxst', 'wam', 'umd', 'edu', 'where', 'my', 'thing',\n",
       "        'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host',\n",
       "        'rac3', 'organization', 'university', 'of', 'maryland', 'college',\n",
       "        'park', 'lines', '15', 'was', 'wondering', 'if', 'anyone', 'out',\n",
       "        'there', 'could', 'enlighten', 'me', 'on', 'saw', 'the', 'other',\n",
       "        'day', 'it', 'door', 'sports', 'looked', 'to', 'be', 'late', '60s',\n",
       "        'early', '70s', 'called', 'bricklin', 'doors', 'were', 'really',\n",
       "        'small', 'in', 'addition', 'front', 'bumper', 'separate', 'rest',\n",
       "        'body', 'all', 'know', 'can', 'tellme', 'model', 'name', 'engine',\n",
       "        'specs', 'years', 'production', 'made', 'history', 'or',\n",
       "        'whatever', 'info', 'you', 'have', 'funky', 'looking', 'please',\n",
       "        'mail', 'thanks', 'il', 'brought', 'by', 'your', 'neighborhood'],\n",
       "       dtype='<U180'),\n",
       " array(['from', 'edu', 'subject', 'this', 'nntp', 'posting', 'host',\n",
       "        'organization', 'university', 'of', 'lines', 'if', 'on', 'the',\n",
       "        'day', 'to', 'be', 'in', 'you', 'have', 'please', 'thanks', 'your',\n",
       "        'guykuo', 'carson', 'washington', 'guy', 'kuo', 'si', 'clock',\n",
       "        'poll', 'final', 'call', 'summary', 'for', 'reports', 'keywords',\n",
       "        'acceleration', 'upgrade', 'article', 'shelley', '1qvfo9innc3s',\n",
       "        '11', 'fair', 'number', 'brave', 'souls', 'who', 'upgraded',\n",
       "        'their', 'oscillator', 'shared', 'experiences', 'send', 'brief',\n",
       "        'message', 'detailing', 'with', 'procedure', 'top', 'speed',\n",
       "        'attained', 'cpu', 'rated', 'add', 'cards', 'and', 'adapters',\n",
       "        'heat', 'sinks', 'hour', 'usage', 'per', 'floppy', 'disk',\n",
       "        'functionality', '800', 'floppies', 'are', 'especially',\n",
       "        'requested', 'will', 'summarizing', 'next', 'two', 'days', 'so',\n",
       "        'network', 'knowledge', 'base', 'done', 'haven', 'answered'],\n",
       "       dtype='<U180'),\n",
       " array(['from', 'edu', 'my', 'subject', 'what', 'is', 'this',\n",
       "        'organization', 'university', 'of', 'lines', 'was', 'wondering',\n",
       "        'if', 'out', 'there', 'could', 'on', 'the', 'day', 'it', 'to',\n",
       "        'be', 'really', 'in', 'all', 'know', 'can', 'or', 'info', 'you',\n",
       "        'have', 'looking', 'thanks', 'summary', 'for', 'who', 'with',\n",
       "        'and', 'disk', 'are', 'next', 'network', 'haven', 'twillis', 'ec',\n",
       "        'ecn', 'purdue', 'thomas', 'willis', 'pb', 'questions',\n",
       "        'engineering', 'computer', 'distribution', 'usa', '36', 'well',\n",
       "        'folks', 'mac', 'plus', 'finally', 'gave', 'up', 'ghost',\n",
       "        'weekend', 'after', 'starting', 'life', 'as', '512k', 'way',\n",
       "        'back', '1985', 'sooo', 'market', 'new', 'machine', 'bit',\n",
       "        'sooner', 'than', 'intended', 'into', 'picking', 'powerbook',\n",
       "        '160', 'maybe', '180', 'bunch', 'that', 'hopefully', 'somebody',\n",
       "        'answer', 'does', 'anybody', 'any', 'dirt', 'when', 'round',\n",
       "        'introductions', 'expected', 'heard', '185c', 'supposed', 'make',\n",
       "        'an', 'appearence', 'summer', 'but', 'anymore', 'since', 'don',\n",
       "        'access', 'macleak', 'had', 'more', 'has', 'rumors', 'about',\n",
       "        'price', 'drops', 'line', 'like', 'ones', 'duo', 'just', 'went',\n",
       "        'through', 'recently', 'impression', 'display', 'probably',\n",
       "        'swing', 'got', '80mb', 'rather', '120', 'feel', 'how', 'much',\n",
       "        'better', 'yea', 'looks', 'great', 'store', 'wow', 'good',\n",
       "        'solicit', 'some', 'opinions', 'people', 'use', 'its', 'worth',\n",
       "        'taking', 'size', 'money', 'hit', 'get', 'active', 'realize',\n",
       "        'real', 'subjective', 'question', 've', 'only', 'played', 'around',\n",
       "        'machines', 'breifly', 'figured', 'actually', 'uses', 'daily',\n",
       "        'might', 'prove', 'helpful', 'hellcats', 'perform', 'advance',\n",
       "        'email', 'll', 'post', 'news', 'reading', 'time', 'at', 'premium',\n",
       "        'finals', 'corner', 'tom', 'electrical', 'convictions',\n",
       "        'dangerous', 'enemies', 'truth', 'lies', 'nietzsche'],\n",
       "       dtype='<U180'),\n",
       " array(['from', 'edu', 'thing', 'subject', 'is', 'this', 'nntp', 'posting',\n",
       "        'host', 'organization', 'of', 'lines', 'anyone', 'me', 'the', 'it',\n",
       "        'to', 'really', 'in', 'know', 'you', 'have', 'article', 'number',\n",
       "        'with', 'computer', 'distribution', 'as', 'that', 'about', 'like',\n",
       "        'just', 'got', 'looks', 'some', 'get', 'only', 'jgreen', 'amber',\n",
       "        'joe', 'green', 're', 'weitek', 'p9000', 'harris', 'systems',\n",
       "        'division', '14', 'world', 'ssd', 'csd', 'com', 'newsreader',\n",
       "        'tin', 'version', 'pl9', 'robert', 'kyanko', 'rob', 'rjck', 'uucp',\n",
       "        'wrote', 'abraxis', 'iastate', 'writes', '734340159', 'class1',\n",
       "        'graphics', 'chip', 'far', 'low', 'level', 'stuff', 'goes',\n",
       "        'pretty', 'nice', 'quadrilateral', 'fill', 'command', 'requires',\n",
       "        'four', 'points', 'do', 'address', 'phone', 'information',\n",
       "        'corporation', 'scares', 'person', 'no', 'sense', 'humor',\n",
       "        'jonathan', 'winters'], dtype='<U180')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.inverse_transform(X[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeff/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8780380026513478"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newsgroups_train['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graphics     1.573041\n",
       "image        1.002384\n",
       "images       0.976303\n",
       "3d           0.885399\n",
       "24           0.774670\n",
       "files        0.751026\n",
       "pov          0.717016\n",
       "library      0.691739\n",
       "package      0.652439\n",
       "3do          0.645722\n",
       "file         0.642139\n",
       "tiff         0.612601\n",
       "polygon      0.598174\n",
       "imagine      0.583751\n",
       "animation    0.571993\n",
       "cview        0.568688\n",
       "42           0.562986\n",
       "gif          0.546851\n",
       "vga          0.532252\n",
       "color        0.514511\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeficients = pd.Series(lr.coef_[1], vectorizer.get_feature_names()).sort_values(ascending = False)\n",
    "coeficients[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**corpus**\n",
    "\n",
    "`vocabulary`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* vectorizer vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's lost from BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[['From: lerxst@wam.umd.edu', 'lerxst@wam.umd.edu (where', 'where's my']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = ENGLISH_STOP_WORDS, ngram_range=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ngrams = vectorizer.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 1186545)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ngrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cbr serial', 255199),\n",
       " ('number jh2sc281xpm100187', 758092),\n",
       " ('jh2sc281xpm100187 engine', 594925),\n",
       " ('engine number', 412653),\n",
       " ('number 2101240', 757683),\n",
       " ('2101240 turn', 44172),\n",
       " ('signals mirrors', 969551),\n",
       " ('mirrors lights', 710599),\n",
       " ('lights taped', 644290),\n",
       " ('taped track', 1039529),\n",
       " ('track riders', 1072631),\n",
       " ('riders session', 912805),\n",
       " ('session willow', 958492),\n",
       " ('willow springs', 1146450),\n",
       " ('springs tomorrow', 996569),\n",
       " ('tomorrow guess', 1068261),\n",
       " ('ll miss', 655714),\n",
       " ('miss help', 711308),\n",
       " ('help baby', 527863),\n",
       " ('baby kjg', 190499)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectorizer.vocabulary_.items())[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Stop words \n",
    "\n",
    "Stop words - exclude common words from our features\n",
    "\n",
    "* Downside\n",
    "* Stop words can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Ngrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"On hold\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes Newsgroups](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NLP Newsgroups](https://medium.com/@siyao_sui/nlp-with-the-20-newsgroups-dataset-ab35cd0ea902)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[FastAI NLP](https://github.com/fastai/course-nlp/blob/master/2-svd-nmf-topic-modeling.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sklearn text data](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes Classifier](https://towardsdatascience.com/the-naive-bayes-classifier-e92ea9f47523)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
