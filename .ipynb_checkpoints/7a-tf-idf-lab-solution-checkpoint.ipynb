{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, build up both the bag of words and the term frequency inverse document frequencies from scratch in Python.  Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/jigsawlabs-student/nlp-text-representation/master/coconut_water.csv\"\n",
    "coconut_df = pd.read_csv(url, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47836</th>\n",
       "      <td>47837</td>\n",
       "      <td>B004SRH2B6</td>\n",
       "      <td>AKACGHPVILE9R</td>\n",
       "      <td>Sophronia \"Euphemia\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1314144000</td>\n",
       "      <td>Switched to O.N.E.</td>\n",
       "      <td>Must admit the taste of O.N.E. coconut water i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47837</th>\n",
       "      <td>47838</td>\n",
       "      <td>B004SRH2B6</td>\n",
       "      <td>A2GO0AIHB846UX</td>\n",
       "      <td>vinny</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1313884800</td>\n",
       "      <td>WOW!!</td>\n",
       "      <td>I love this stuff!  Perfect blend of dark choc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id   ProductId          UserId           ProfileName  \\\n",
       "47836  47837  B004SRH2B6   AKACGHPVILE9R  Sophronia \"Euphemia\"   \n",
       "47837  47838  B004SRH2B6  A2GO0AIHB846UX                 vinny   \n",
       "\n",
       "       HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "47836                     1                       1      1  1314144000   \n",
       "47837                     1                       1      5  1313884800   \n",
       "\n",
       "                  Summary                                               Text  \n",
       "47836  Switched to O.N.E.  Must admit the taste of O.N.E. coconut water i...  \n",
       "47837               WOW!!  I love this stuff!  Perfect blend of dark choc...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coconut_df[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first couple of reviews, notice that we collected both text and a score for each review.  The score is the Amazon rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words to Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with writing a function that performs bag of words, and then we'll move to term frequency.  To get started, let's assign the `text` column to a variable called `documents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = coconut_df.Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now bag of words is essentially a histogram.  In the `bag_of_words` method below, create a dictionary that consists of each word in a document, followed by the number of times that word appears."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Take a look at the solution below to see the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(document):\n",
    "    terms = [term.lower() for term in document.split()]\n",
    "    dictionary = dict.fromkeys(terms, 0)\n",
    "    for term in terms:\n",
    "        dictionary[term] += 1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'must': 1,\n",
       " 'admit': 1,\n",
       " 'the': 2,\n",
       " 'taste': 1,\n",
       " 'of': 2,\n",
       " 'o.n.e.': 1,\n",
       " 'coconut': 2,\n",
       " 'water': 1,\n",
       " 'is': 1,\n",
       " 'better.': 1,\n",
       " 'took': 1,\n",
       " 'a': 1,\n",
       " 'long': 1,\n",
       " 'time': 1,\n",
       " 'to': 1,\n",
       " 'get': 1,\n",
       " 'through': 1,\n",
       " 'supply': 1,\n",
       " 'water.': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_document = documents.iloc[0]\n",
    "bag_of_words(first_document)\n",
    "\n",
    "# {'must': 1,\n",
    "#  'admit': 1,\n",
    "#  'the': 2,\n",
    "#  'taste': 1,\n",
    "#  'of': 2,\n",
    "#  'o.n.e.': 1,\n",
    "#  'coconut': 2,\n",
    "#  'water': 1,\n",
    "#  'is': 1,\n",
    "#  'better.': 1,\n",
    "#  'took': 1,\n",
    "#  'a': 1,\n",
    "#  'long': 1,\n",
    "#  'time': 1,\n",
    "#  'to': 1,\n",
    "#  'get': 1,\n",
    "#  'through': 1,\n",
    "#  'supply': 1,\n",
    "#  'water.': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's incorporate use of spacy.  Remember that we can use spacy to token and lemmatize our document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First let's import and load up spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see the document below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Must admit the taste of O.N.E. coconut water is better.  Took a long time to get through the supply of coconut water."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(first_document)\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the bag of words model to return a historgram of the lemma's of the words, and only include the word if it is not a stop word, according to spacy, and it *is* an alphabetical term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_spacy(document):\n",
    "    terms = [term.lemma_ for term in nlp(document) if term.is_alpha and not term.is_stop]\n",
    "    dictionary = dict.fromkeys(terms, 0)\n",
    "    for term in terms:\n",
    "        dictionary[term] += 1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admit': 1,\n",
       " 'taste': 1,\n",
       " 'coconut': 2,\n",
       " 'water': 2,\n",
       " 'well': 1,\n",
       " 'take': 1,\n",
       " 'long': 1,\n",
       " 'time': 1,\n",
       " 'supply': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_spacy(first_document)\n",
    "\n",
    "# {'admit': 1,\n",
    "#  'taste': 1,\n",
    "#  'coconut': 2,\n",
    "#  'water': 2,\n",
    "#  'well': 1,\n",
    "#  'take': 1,\n",
    "#  'long': 1,\n",
    "#  'time': 1,\n",
    "#  'supply': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move from bag of words to term frequency.  Remember the term frequency calculates the percentage of times each word appears in the document. \n",
    "> Below, update the bag of words function to return the term frequency of each word in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(document):\n",
    "    terms = [term.lemma_ for term in nlp(document) if term.is_alpha and not term.is_stop]\n",
    "    doc_length = len(terms)\n",
    "    dictionary = dict.fromkeys(terms, 0)\n",
    "    for term in terms:\n",
    "        dictionary[term] += 1/doc_length\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admit': 0.09090909090909091,\n",
       " 'taste': 0.09090909090909091,\n",
       " 'coconut': 0.18181818181818182,\n",
       " 'water': 0.18181818181818182,\n",
       " 'well': 0.09090909090909091,\n",
       " 'take': 0.09090909090909091,\n",
       " 'long': 0.09090909090909091,\n",
       " 'time': 0.09090909090909091,\n",
       " 'supply': 0.09090909090909091}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequency(first_document)\n",
    "\n",
    "# {'admit': 0.09090909090909091,\n",
    "#  'taste': 0.09090909090909091,\n",
    "#  'coconut': 0.18181818181818182,\n",
    "#  'water': 0.18181818181818182,\n",
    "#  'well': 0.09090909090909091,\n",
    "#  'take': 0.09090909090909091,\n",
    "#  'long': 0.09090909090909091,\n",
    "#  'time': 0.09090909090909091,\n",
    "#  'supply': 0.09090909090909091}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use inverse document frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that: \n",
    "    \n",
    "$\\text{idf(term)} = \\log(\\frac{\\text{# of documents}}{\\text{# of documents with term}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So the *larger* the number of documents with the term, the smaller the number idf of the term.  The idf is the inverse of the proportion of documents with term, then logged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll provide a dictionary of the document frequency for you:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Writing a function that calculates the actual document frequency is tricky as we'd need to coerce each word in each document to the lemmatized form.  And then we'd see the number of documents with the lemmatized word.  So we just provide a dictionary with some made up frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_frequency_dict = {'salty': 5, 'water': 300, 'coconut': 250, 'taste': 280, 'sweet': 150}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So the above says that 300 of the documents has the word water, and five of the documents had the word salty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def inverse_document_frequency(term, doc_length = 456):\n",
    "    return np.log(doc_length/document_frequency_dict[term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41871033485818504"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_document_frequency('water', doc_length = 456)\n",
    "# 0.41871033485818504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.513054897080286"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_document_frequency('salty', doc_length = 456)\n",
    "# 4.513054897080286"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the more frequent a word, the lower the inverse document frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Dictionary of Inverse Document Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the inverse document frequency of any given term is constant throughout the corpus, regardless of the particular document.  So, we can create a dictionary of each word along with the inverse document frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'salty': 4.513054897080286,\n",
       " 'water': 0.41871033485818504,\n",
       " 'coconut': 0.6010318916521397,\n",
       " 'taste': 0.4877032063451365,\n",
       " 'sweet': 1.1118575154181303}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_dict = dict([(term, inverse_document_frequency(term)) for term in list(document_frequency_dict.keys())])\n",
    "idf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we saw that inverse document frequency is constant throughout an entire corpus, as it is measuring the proportion of times that a term occurs in a document in the corpus.\n",
    "\n",
    "Term frequency, by contrast, is per document.  And putting the two components together, to calculate a word's importance in the document we multiply how frequently the word appears in a document by the inverse of how many document the word appears in generally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function called `tf_idf` that takes in a term and a document and returns the `tf_idf` of that term for the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(term, document):\n",
    "    tf_term = term_frequency(document)[term]\n",
    "    return tf_term*idf_dict[term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07612915179239728"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf('water', first_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10927852575493449"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf('coconut', first_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admit': 0.09090909090909091,\n",
       " 'taste': 0.09090909090909091,\n",
       " 'coconut': 0.18181818181818182,\n",
       " 'water': 0.18181818181818182,\n",
       " 'well': 0.09090909090909091,\n",
       " 'take': 0.09090909090909091,\n",
       " 'long': 0.09090909090909091,\n",
       " 'time': 0.09090909090909091,\n",
       " 'supply': 0.09090909090909091}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_frequency(first_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that even though `coconut` and `water` appear with the same frequency in the document, coconut is weighted more because it occurs less frequently throughout the corpus.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we explored text representation of a document through TF-IDF.  As the name implies, this has two components.  The term frequency is per document, and calculates the proportion of times that a word appears in the document.  The inverse document frequency, by contrast is a score that stays constant throughout the corpus and is calculated by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{idf(term)} = \\log(\\frac{\\text{# of documents}}{\\text{# of documents with term}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's the inverse of the proportion of documents with term, and then logged."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
