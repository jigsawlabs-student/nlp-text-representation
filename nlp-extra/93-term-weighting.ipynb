{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Want to see how Q is close to D\n",
    "* $\\sum Q_w \\cdot D_w$ where $Q_w$ is weight of word in query, and $D_w$ is weight of word in document.  Instead of weight, can also think of coordinate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* But how do we set Q_w, and D_w, this is what's important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So term weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Word Overlap Algorithm\n",
    "\n",
    "* 1. Presence and absence most important (so doesn't matter how many times it's present, or length of document)\n",
    "\n",
    "2. But repetitions are important \n",
    "    * But if there's a word that occurs multiple times, then maybe more important \n",
    "    * So could have frequency be the weight\n",
    "    So term frequency in w * term frequency in d\n",
    "    \n",
    "* But the problem is that if just base on term frequency will bias long documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* But a tweet will never have a repetition, while a book will\n",
    "* So we normalize by the document length D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* note that we don't normalize by the query, because there's only one query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So this is rank invariant, because will change the numbers, but won't change the rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$s(Q, D) = \\sum tf_{wQ} \\cdot \\frac{tf}{|D|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is the term frequency component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is the idea that some words carry a lot of content in them \n",
    "    * Aardvark, cryogenic, or jaccard\n",
    "        * Once we see this word, we know what the rest of the content is\n",
    "    * Eg. Said, Big, Went\n",
    "\n",
    "* So we would like to make some words more important\n",
    "    * So give more weight to rare words\n",
    "* And if have a word that's only 3 or 4 times, then a very useful word\n",
    "    * So inverse document frequency\n",
    "        * Count the number of different documents that contain a word (as opposed to collection frequency, the number of different collections)\n",
    "        * Give more weight to rare words $log \\frac{C}{df_w}$, where \n",
    "        * |C| = num docs in collection\n",
    "        * $df_w$ number of docs containing word \n",
    "        * So more docs that contain the word, the lower the score.  Then log of that.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./tf-idf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why take the log \n",
    "    * The range of values, because the range of values it can take is a lot higher than the range of term frequencies\n",
    "    * So you place TF, and IDF on the same scale by taking the log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./tf-idf-example.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the query vector just gets multiplied by these weights.  Do a dot product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q = \"angry aardvark\"\n",
    "* D1 = \"angry....aardvark\"\n",
    "* D2 = \"aardvark...aardvark\"\n",
    "\n",
    "So we have \n",
    "* $d1 = [1, 1]$\n",
    "* $d2 = [0, 2]$\n",
    "\n",
    "* $tfd1 = [1, 1] \\cdot [1, 1] = 2$\n",
    "* $d2 = [0, 2] \\cdot [1, 1] = 2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So the point is that the first occurrence is more important than a repeat \n",
    "    * If you see an aardvark once, we are much more likely to see it again (if think about the level of surprise it's much higher)\n",
    "    * So we squash frequencies \n",
    "        $\\frac {tf}{tf + k}$\n",
    "        \n",
    "     * K is a hyperparameter, we can use to control how aggresive the squashing is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/(2 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that a small k has a large squash ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Essentially, with a small k term frequency is binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the k, depend on the length of the document\n",
    "* For long documents, we have a large value of k, so that the importance grows steadily w/ each occurrence\n",
    "\n",
    "* And with short documents, then repetitions not that important\n",
    "* So take $\\frac{doc length}{avg doc length}$, so k is that.\n",
    "\n",
    "* If much larger than the average, then it's smooth tf.\n",
    "* Note still have a $k$ hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf -idf weighted sum \n",
    "\n",
    "* For short queries, so for short engines \n",
    "* So a search engine, will use something like this\n",
    "\n",
    "* And this is what you use with a short query and long documents \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./tf-idf-weighted.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
