{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we'll practice using the bag of words model using a corpus that consists of tweets about an airline.  Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {'negative': 0, 'neutral': 1, 'positive': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.airline_sentiment.map(sentiment_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employ Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectors = bow.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vectors.toarray()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7956284153005464"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst           2.214460\n",
       "nothing         1.543403\n",
       "delayed         1.463210\n",
       "hours           1.414857\n",
       "ridiculous      1.399412\n",
       "terrible        1.362820\n",
       "fail            1.351004\n",
       "suck            1.347511\n",
       "unacceptable    1.335372\n",
       "sucks           1.291287\n",
       "fix             1.266558\n",
       "answer          1.259342\n",
       "unless          1.231424\n",
       "paid            1.229213\n",
       "hold            1.228098\n",
       "rude            1.219338\n",
       "worse           1.208478\n",
       "disappointed    1.204609\n",
       "luggage         1.179982\n",
       "frustrated      1.179896\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lr.coef_[0], bow.get_feature_names()).sort_values(ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thank         2.224737\n",
       "awesome       2.152502\n",
       "thanks        2.013645\n",
       "great         1.828529\n",
       "worries       1.812265\n",
       "thnx          1.693800\n",
       "amazing       1.672030\n",
       "excellent     1.670677\n",
       "best          1.667961\n",
       "love          1.666248\n",
       "cool          1.548519\n",
       "appreciate    1.522806\n",
       "thx           1.501574\n",
       "wonderful     1.489044\n",
       "kudos         1.363512\n",
       "thankful      1.302682\n",
       "loved         1.221681\n",
       "refunded      1.215347\n",
       "happy         1.166732\n",
       "sweet         1.152855\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lr.coef_[-1], bow.get_feature_names()).sort_values(ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "ngram_vectorizor = CountVectorizer(ngram_range = (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ngrams = ngram_vectorizor.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ngrams, y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8024590163934426"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_ngrams = LogisticRegression(max_iter = 1000).fit(X_train, y_train)\n",
    "\n",
    "lr_ngrams.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delayed     1.358320\n",
       "worst       1.353864\n",
       "suck        1.214716\n",
       "nothing     1.205090\n",
       "delay       1.176671\n",
       "hours       1.168483\n",
       "sucks       1.125183\n",
       "doesn       1.124958\n",
       "luggage     1.115510\n",
       "not         1.098714\n",
       "lost        1.088311\n",
       "no          1.084192\n",
       "why         1.073450\n",
       "stop        1.024607\n",
       "bags        0.947827\n",
       "on hold     0.934132\n",
       "again       0.920254\n",
       "hour        0.916932\n",
       "terrible    0.906476\n",
       "missing     0.905110\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lr_ngrams.coef_[0], ngram_vectorizor.get_feature_names()).sort_values(ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[5 part Spacy Tutorial](https://medium.com/@makcedward/nlp-pipeline-stop-words-part-5-d6770df8a936)\n",
    "\n",
    "[Kaggle Amazon Food Reviews](https://www.kaggle.com/snap/amazon-fine-food-reviews)\n",
    "\n",
    "[Spacy](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
